{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mMQAnaX3fXO",
        "outputId": "faede616-9c7b-4203-f7f6-9053ff8ac368"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxFI-x8I6Uiu"
      },
      "source": [
        "## 단어 단위 토크나이징"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68A4q7WS5coO",
        "outputId": "9725dfd7-4cc4-4017-c4f1-1778f7da85fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sentence = \"Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
        "\n",
        "print(word_tokenize(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuV8eSnD6EZb",
        "outputId": "1fdf5125-1129-400f-99ae-30ae09cae318"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word_tokenize(sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt6yv4Xx6Ytr"
      },
      "source": [
        "## 문장 단위 토크나이징"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A03Mdu5O6aqN",
        "outputId": "e7622470-94e9-422d-879c-9ac9c034f65e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "paragraph = \"Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
        "\n",
        "sent_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laX1Hl9u6LMQ",
        "outputId": "1ff2e439-7a4e-4baa-b4b6-3898e4ac3478"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sent_tokenize(paragraph))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nX2nOCe6_z8",
        "outputId": "042ee553-5b46-4964-8bcc-ce1cf3911d42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['NLTK is a leading platform for building Python programs to work with human language data.',\n",
              " 'It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.',\n",
              " 'Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike.',\n",
              " 'NLTK is available for Windows, Mac OS X, and Linux.',\n",
              " 'Best of all, NLTK is a free, open source, community-driven project.',\n",
              " 'NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.”']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paragraph = '''NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\n",
        "\n",
        "Thanks to a hands-on guide introducing programming fundamentals alongside topics in computational linguistics, plus comprehensive API documentation, NLTK is suitable for linguists, engineers, students, educators, researchers, and industry users alike. NLTK is available for Windows, Mac OS X, and Linux. Best of all, NLTK is a free, open source, community-driven project.\n",
        "\n",
        "NLTK has been called “a wonderful tool for teaching, and working in, computational linguistics using Python,” and “an amazing library to play with natural language.”'''\n",
        "\n",
        "sent_tokenize(paragraph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5cOMKiS7NF8",
        "outputId": "1893d653-7576-4113-f383-d3d8871bde9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(sent_tokenize(paragraph))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhr4-L_Z78c4"
      },
      "source": [
        "### 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiICtVzv77z2",
        "outputId": "4f1d32ac-1dcd-47ed-dc1a-8550bf627c9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A', 'paragraph', 'is', 'a', 'collection', 'of', 'words', 'strung', 'together', 'to', 'make', 'a', 'longer', 'unit', 'than', 'a', 'sentence', '.', 'Several', 'sentences', 'often', 'make', 'a', 'paragraph', '.', 'There', 'are', 'normally', 'three', 'to', 'eight', 'sentences', 'in', 'a', 'paragraph', '.', 'Paragraphs', 'can', 'start', 'with', 'a', 'five-space', 'indentation', 'or', 'by', 'skipping', 'a', 'line', 'and', 'then', 'starting', 'over', '.', 'This', 'makes', 'it', 'simpler', 'to', 'tell', 'when', 'one', 'paragraph', 'ends', 'and', 'the', 'next', 'starts', 'simply', 'it', 'has', '3-9', 'lines', '.', 'A', 'topic', 'phrase', 'appears', 'in', 'most', 'ordered', 'types', 'of', 'writing', ',', 'such', 'as', 'essays', '.', 'This', 'paragraph', \"'s\", 'topic', 'sentence', 'informs', 'the', 'reader', 'about', 'the', 'topic', 'of', 'the', 'paragraph', '.', 'In', 'most', 'essays', ',', 'numerous', 'paragraphs', 'make', 'statements', 'to', 'support', 'a', 'thesis', 'statement', ',', 'which', 'is', 'the', 'essay', \"'s\", 'fundamental', 'point', '.', 'Paragraphs', 'may', 'signal', 'when', 'the', 'writer', 'changes', 'topics', '.', 'Each', 'paragraph', 'may', 'have', 'a', 'number', 'of', 'sentences', ',', 'depending', 'on', 'the', 'topic', '.']\n",
            "148\n",
            "['A paragraph is a collection of words strung together to make a longer unit than a sentence.', 'Several sentences often make a paragraph.', 'There are normally three to eight sentences in a paragraph.', 'Paragraphs can start with a five-space indentation or by skipping a line and then starting over.', 'This makes it simpler to tell when one paragraph ends and the next starts simply it has 3-9 lines.', 'A topic phrase appears in most ordered types of writing, such as essays.', \"This paragraph's topic sentence informs the reader about the topic of the paragraph.\", \"In most essays, numerous paragraphs make statements to support a thesis statement, which is the essay's fundamental point.\", 'Paragraphs may signal when the writer changes topics.', 'Each paragraph may have a number of sentences, depending on the topic.']\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "text = '''A paragraph is a collection of words strung together to make a longer unit than a sentence. Several sentences often make a paragraph. There are normally three to eight sentences in a paragraph. Paragraphs can start with a five-space indentation or by skipping a line and then starting over. This makes it simpler to tell when one paragraph ends and the next starts simply it has 3-9 lines.\n",
        "\n",
        "A topic phrase appears in most ordered types of writing, such as essays. This paragraph's topic sentence informs the reader about the topic of the paragraph. In most essays, numerous paragraphs make statements to support a thesis statement, which is the essay's fundamental point.\n",
        "\n",
        "Paragraphs may signal when the writer changes topics. Each paragraph may have a number of sentences, depending on the topic.'''\n",
        "\n",
        "word = word_tokenize(text)\n",
        "sent = sent_tokenize(text)\n",
        "\n",
        "print(word)\n",
        "print(len(word))\n",
        "print(sent)\n",
        "print(len(sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRixYjEW8aNc"
      },
      "source": [
        "## SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TseZ_zI78ewu"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "spacy.__version__\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgMeXHLL9QT3",
        "outputId": "0043fd90-ac8d-4948-c4d4-2f9c2aeff51a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spacy.lang.en.English"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CH-3Go3_-Ds6",
        "outputId": "ebe4955c-7787-465e-a2cf-92490a40b518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n",
            "Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\n",
            "<class 'str'> <class 'spacy.tokens.doc.Doc'>\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
        "print(sentence)\n",
        "\n",
        "doc_spacy = nlp(sentence)\n",
        "print(doc_spacy)\n",
        "print(type(sentence), type(doc_spacy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3kJ5KKO-tfr",
        "outputId": "e2988de9-5ee1-4c8d-b22d-7b4e56bff091"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(doc_spacy)      # 토큰 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGo1A64S_B4m",
        "outputId": "c97b8771-99f6-4aaa-a2da-feb43a8ab6d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Natural, language, processing, (, NLP, ), is, a, subfield, of, computer, science, ,, information, engineering, ,, and, artificial, intelligence, concerned, with, the, interactions, between, computers, and, human, (, natural, ), languages, ,, in, particular, how, to, program, computers, to, process, and, analyze, large, amounts, of, natural, language, data, .]\n"
          ]
        }
      ],
      "source": [
        "print(list(doc_spacy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdosQXFX_qKY",
        "outputId": "b009ede1-d671-4bc2-8702-6d8f28356727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Natural, language, processing, (, NLP, ), is, a, subfield, of, computer, science, ,, information, engineering, ,, and, artificial, intelligence, concerned, with, the, interactions, between, computers, and, human, (, natural, ), languages, ,, in, particular, how, to, program, computers, to, process, and, analyze, large, amounts, of, natural, language, data, .]\n",
            "<class 'spacy.tokens.token.Token'>\n"
          ]
        }
      ],
      "source": [
        "# Token 객체\n",
        "word_tokenized_sentence = [token for token in doc_spacy]\n",
        "print(word_tokenized_sentence)\n",
        "print(type(word_tokenized_sentence[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glLLBxPH_QPo",
        "outputId": "8f0596d8-eadd-4ed6-b603-10e2a6031986"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n",
            "<class 'str'>\n"
          ]
        }
      ],
      "source": [
        "# String으로 변환\n",
        "word_tokenized_sentence = [token.text for token in doc_spacy]\n",
        "print(word_tokenized_sentence)\n",
        "print(type(word_tokenized_sentence[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTlHmaX-_15j",
        "outputId": "46f83166-8ce7-4257-b193-7e83a5ccbeea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_tokenize_list = [sent.text for sent in doc_spacy.sents]\n",
        "sentence_tokenize_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PnHRv2AETNO"
      },
      "outputs": [],
      "source": [
        "import konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e29dYYVHMe7p"
      },
      "outputs": [],
      "source": [
        "from konlpy.tag import Okt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxSv77TpNtmw"
      },
      "outputs": [],
      "source": [
        "okt = Okt()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pcO5zLKNy9l",
        "outputId": "4aa72234-cadc-4614-cbea-20f668fba265"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '해야지', 'ㅎㅎㅎ']"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = '한글 자연어 처리는 재밌다 이제부터 열심히 해야지 ㅎㅎㅎ'\n",
        "\n",
        "# 형태소로 묶기\n",
        "okt.morphs(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbQz6a3vSpw2",
        "outputId": "55d64f76-2df9-46e7-e25e-8e1fea5cb3c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '하다', 'ㅎㅎㅎ']"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 어간 추출\n",
        "okt.morphs(text, stem=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_2wd67LS1WY",
        "outputId": "77a39392-95b5-4b90-8005-e8d5435f527e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['한글', '자연어', '처리', '이제']"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 명사 추출\n",
        "okt.nouns(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFOKjHf7S6U2",
        "outputId": "56244f1c-c508-46b6-a2cf-04220a4a4fd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['한글', '한글 자연어', '한글 자연어 처리', '이제', '자연어', '처리']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 어절 추출\n",
        "okt.phrases(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm5vxC2jTQSd",
        "outputId": "3eb2399e-d2a9-4d2d-bab3-17f35e93688f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('는', 'Josa'), ('재밌다', 'Adjective'), ('이제', 'Noun'), ('부터', 'Josa'), ('열심히', 'Adverb'), ('해야지', 'Verb'), ('ㅎㅎㅎ', 'KoreanParticle')]\n"
          ]
        }
      ],
      "source": [
        "# 품사 태깅\n",
        "print(okt.pos(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJBPsGb2T73e"
      },
      "source": [
        "# 한국 법률 말뭉치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcM9zyJKT60S"
      },
      "outputs": [],
      "source": [
        "from konlpy.corpus import kolaw\n",
        "\n",
        "const = kolaw.open('constitution.txt').read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGJeC6_RUVv6",
        "outputId": "2873f6b6-bb49-4062-b640-f118636e3bfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18884"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 글자 수\n",
        "len(const)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16Hfdq7_UekA"
      },
      "source": [
        "##대한민국 국회 의안 말뭉치"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeDP5-zcUjdV"
      },
      "outputs": [],
      "source": [
        "from konlpy.corpus import kobill\n",
        "kobill_s = kobill.open()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4KGxvU8XGOZ",
        "outputId": "07643c3a-58a0-4832-b06c-06939af989b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -U gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyOIuGfzXPmR"
      },
      "source": [
        "# 불용어 처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD5QGTm8XTEg",
        "outputId": "10bd87a5-a89c-4fe2-9446-7291277c54c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "불용어 제거 미적용: ['One', 'of', 'the', 'first', 'things', 'that', 'we', 'ask', 'ourselves', 'is', 'what', 'are', 'the', 'pros', 'and', 'cons', 'of', 'any', 'task', 'we', 'perform', '.'] \n",
            "\n",
            "불용어 제거 적용: ['One', 'first', 'things', 'ask', 'pros', 'cons', 'task', 'perform', '.']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sample_text = 'One of the first things that we ask ourselves is what are the pros and cons of any task we perform.'\n",
        "text_tokens = word_tokenize(sample_text)\n",
        "\n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
        "print('불용어 제거 미적용:', text_tokens, '\\n')\n",
        "print('불용어 제거 적용:', tokens_without_sw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8siO9CO-ZA6F",
        "outputId": "79668b9a-7895-4047-b724-ddfd3cbd6f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "179\n"
          ]
        }
      ],
      "source": [
        "# 현재 불용어에 등록된 단어들\n",
        "print(stopwords.words('english'))\n",
        "print(len(stopwords.words('english')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq-73tUvaqQI"
      },
      "source": [
        "# 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCHJgN-watAe",
        "outputId": "573bf09a-5d90-485d-c993-44273b55178f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "obess obsses\n",
            "standard standard\n",
            "nation nation\n",
            "absent absent\n",
            "tribal tribalic\n"
          ]
        }
      ],
      "source": [
        "#포터 알고리즘\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "print(stemmer.stem('obesses'),stemmer.stem('obssesed'))\n",
        "print(stemmer.stem('standardizes'),stemmer.stem('standardization'))\n",
        "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
        "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
        "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
